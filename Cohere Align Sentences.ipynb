{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "tZ9Ligkx-MyX",
        "aFZd8JwpoVKA",
        "NvLKZhS58yeJ",
        "xnVuZQK29Alj",
        "lJob25us87FM",
        "NVhIuJTh9Ewn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Miscellaneous "
      ],
      "metadata": {
        "id": "tZ9Ligkx-MyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttz-Pl6825Wl",
        "outputId": "41e58251-0ca2-4334-aa7d-ff9f6d01838e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive\n",
        "\n",
        "!git clone https://github.com/abumafrim/Cohere-Align.git"
      ],
      "metadata": {
        "id": "UXww1bgneo73",
        "outputId": "b876aa70-6520-4f0b-f109-a8b91ea1d190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cohere-Align'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 90 (delta 44), reused 28 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (90/90), 27.64 KiB | 1.06 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Cohere-Align"
      ],
      "metadata": {
        "id": "kLtm_9Db8V3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cohere"
      ],
      "metadata": {
        "id": "j2jE-g4K8pww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "pYAu2_BOCZEc",
        "outputId": "85a68e71-b963-4d85-e078-d3dcd8a4102f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cohere\n",
            "  Downloading cohere-4.3.1-py3-none-any.whl (32 kB)\n",
            "Collecting aiohttp<4.0,>=3.0\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\n",
            "Collecting backoff<3.0,>=2.0\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->cohere) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->cohere) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->cohere) (3.4)\n",
            "Installing collected packages: multidict, frozenlist, backoff, async-timeout, yarl, aiosignal, aiohttp, cohere\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 backoff-2.2.1 cohere-4.3.1 frozenlist-1.3.3 multidict-6.0.4 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 scripts/cohere_align.py \\\n",
        "  --cohere_api_key '<api_key>' \\\n",
        "  -m 'embed-multilingual-v2.0' \\\n",
        "  -s src.txt \\\n",
        "  -t trg.txt \\\n",
        "  -o cohere \\\n",
        "  --retrieval 'nn' \\\n",
        "  --dot \\\n",
        "  --cuda"
      ],
      "metadata": {
        "id": "ZFzW9cCrCLyB",
        "outputId": "83132ad1-24f1-4fc3-c3ce-5487e6505038",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build source sent to index map: done\n",
            "length of source embedding 14\n",
            "build target word to index map: done\n",
            "length of target embedding 16\n",
            "                                     source sentences                                       translations\n",
            "0                                     Wannan gwaji ne                                     This is a test\n",
            "1                                        Layi na biyu                                        Second line\n",
            "2                                         Ban sani ba                                       I don't know\n",
            "3                                       Sannu da zuwa                                            Welcome\n",
            "4                                     Rabiu yana wasa                                   Rabiu is playing\n",
            "5                                    Maryam tana gudu                                  Maryam is running\n",
            "6                                           Ina wuni?                                        I am hungry\n",
            "7   A zamanin da anyi wani mutum sunanshi Rabiu wa...  In the past, there existed a man named Rabiu w...\n",
            "8                               Bana son wasa da yawa                                   Rabiu is playing\n",
            "9                                      Ciwo babu dadi                                   Rabiu is playing\n",
            "10                             Ina matukar farin ciki                               I am extremely happy\n",
            "11                                      Ina jin yunwa                                        I am hungry\n",
            "12                            Ciwon na mun zafi sosai                         The injury is very painful\n",
            "13                          Gaskiya coding akwai dadi                                     Coding is nice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Laser"
      ],
      "metadata": {
        "id": "aFZd8JwpoVKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install laserembeddings\n",
        "\n",
        "#download the pre-trained autoencoder models:\n",
        "!python -m laserembeddings download-models"
      ],
      "metadata": {
        "id": "27sQ6DOxhJ6c",
        "outputId": "4b39879b-b85f-4358-b993-9baa447d6814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting laserembeddings\n",
            "  Using cached laserembeddings-1.1.2-py3-none-any.whl (13 kB)\n",
            "Collecting subword-nmt<0.4.0,>=0.3.6\n",
            "  Using cached subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Collecting sacremoses==0.0.35\n",
            "  Using cached sacremoses-0.0.35.tar.gz (859 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from laserembeddings) (1.22.4)\n",
            "Collecting transliterate==1.10.2\n",
            "  Using cached transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n",
            "Collecting torch<2.0.0,>=1.0.1.post2\n",
            "  Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.35->laserembeddings) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.35->laserembeddings) (4.65.0)\n",
            "Collecting mock\n",
            "  Using cached mock-5.0.2-py3-none-any.whl (30 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.0.0,>=1.0.1.post2->laserembeddings) (4.5.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.0.1.post2->laserembeddings) (0.40.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.0.1.post2->laserembeddings) (67.7.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=b27122d2587e7b9bebf5dca0affd0b8e099ddc668433acf557d0fe076055f1ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/12/4b/5c9eeed3636a4041c004e859e03429a49105672c7fb09ba6d9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: transliterate, sacremoses, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, mock, subword-nmt, nvidia-cudnn-cu11, torch, laserembeddings\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed laserembeddings-1.1.2 mock-5.0.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 sacremoses-0.0.35 subword-nmt-0.3.8 torch-1.13.1 transliterate-1.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 scripts/laser_align.py \\\n",
        "  -s src.txt \\\n",
        "  -t trg.txt \\\n",
        "  -o cohere \\\n",
        "  --src_lang ha \\\n",
        "  --trg_lang en \\\n",
        "  --retrieval 'nn' \\\n",
        "  --dot \\\n",
        "  --cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzvaAMs504wo",
        "outputId": "3bca66c0-9f54-4362-f4fd-598ebd50d574"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build source sent to index map: done\n",
            "length of source embedding 14\n",
            "build target word to index map: done\n",
            "length of target embedding 16\n",
            "                                     source sentences                                       translations\n",
            "0                                     Wannan gwaji ne                                   Rabiu is playing\n",
            "1                                        Layi na biyu                                   Rabiu is playing\n",
            "2                                         Ban sani ba                                   Rabiu is playing\n",
            "3                                       Sannu da zuwa                                  Mishal is running\n",
            "4                                     Rabiu yana wasa                                   Rabiu is playing\n",
            "5                                    Maryam tana gudu  In the past, there existed a man named Rabiu w...\n",
            "6                                           Ina wuni?                                   Rabiu is playing\n",
            "7   A zamanin da anyi wani mutum sunanshi Rabiu wa...  In the past, there existed a man named Rabiu w...\n",
            "8                               Bana son wasa da yawa  In the past, there existed a man named Rabiu w...\n",
            "9                                      Ciwo babu dadi  In the past, there existed a man named Rabiu w...\n",
            "10                             Ina matukar farin ciki                                       Good morning\n",
            "11                                      Ina jin yunwa  In the past, there existed a man named Rabiu w...\n",
            "12                            Ciwon na mun zafi sosai  In the past, there existed a man named Rabiu w...\n",
            "13                          Gaskiya coding akwai dadi  In the past, there existed a man named Rabiu w...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "NvLKZhS58yeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download FLORES"
      ],
      "metadata": {
        "id": "xnVuZQK29Alj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on flores devtest\n",
        "\n",
        "# download flores\n",
        "!wget --trust-server-names https://tinyurl.com/flores200dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvLzrUgB155Y",
        "outputId": "2125a2a1-f320-463a-e68c-de44335fe501"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-05 16:57:16--  https://tinyurl.com/flores200dataset\n",
            "Resolving tinyurl.com (tinyurl.com)... 172.67.1.225, 104.20.139.65, 104.20.138.65, ...\n",
            "Connecting to tinyurl.com (tinyurl.com)|172.67.1.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dl.fbaipublicfiles.com/nllb/flores200_dataset.tar.gz [following]\n",
            "--2023-05-05 16:57:16--  https://dl.fbaipublicfiles.com/nllb/flores200_dataset.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.249.141.40, 13.249.141.9, 13.249.141.13, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.249.141.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25585843 (24M) [application/x-tar]\n",
            "Saving to: ‘flores200_dataset.tar.gz’\n",
            "\n",
            "flores200_dataset.t 100%[===================>]  24.40M   138MB/s    in 0.2s    \n",
            "\n",
            "2023-05-05 16:57:16 (138 MB/s) - ‘flores200_dataset.tar.gz’ saved [25585843/25585843]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# untar\n",
        "\n",
        "!tar -xvzf flores200_dataset.tar.gz"
      ],
      "metadata": {
        "id": "my86-sUe2MPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate alignment using laser and cohere"
      ],
      "metadata": {
        "id": "lJob25us87FM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 scripts/laser_align.py \\\n",
        "  -s flores200_dataset/devtest/hau_Latn.devtest \\\n",
        "  -t flores200_dataset/devtest/eng_Latn.devtest \\\n",
        "  -o cohere/flores \\\n",
        "  --src_lang ha \\\n",
        "  --trg_lang en \\\n",
        "  --retrieval 'nn' \\\n",
        "  --dot \\\n",
        "  --cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1GujaLr2uVd",
        "outputId": "b272af41-4ca8-409e-c149-ef38bd4f85d5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating output directory: done\n",
            "build source sent to index map: done\n",
            "length of source embedding 1012\n",
            "build target word to index map: done\n",
            "length of target embedding 1012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 scripts/cohere_align.py \\\n",
        "  --cohere_api_key 'lT27lL4uyB6e8KnTl9tRUDjF1TMksqDWKL8oDjHU' \\\n",
        "  -m 'embed-multilingual-v2.0' \\\n",
        "  -s flores200_dataset/devtest/hau_Latn.devtest \\\n",
        "  -t flores200_dataset/devtest/eng_Latn.devtest \\\n",
        "  -o cohere/flores \\\n",
        "  --retrieval 'nn' \\\n",
        "  --dot \\\n",
        "  --cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfyaanSS5hDC",
        "outputId": "a43c8d74-5e24-4cae-9e94-e3cd42151c1e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build source sent to index map: done\n",
            "length of source embedding 1012\n",
            "build target word to index map: done\n",
            "length of target embedding 1012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calculate F1 score"
      ],
      "metadata": {
        "id": "NVhIuJTh9Ewn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import pandas as pd\n",
        "\n",
        "with open('flores200_dataset/devtest/eng_Latn.devtest') as f:\n",
        "  y_true = f.readlines()\n",
        "  y_true = [y.strip() for y in y_true]\n",
        "\n",
        "# cohere f1\n",
        "df = pd.read_csv('cohere/flores/cohere_translations.csv')\n",
        "y_pred = df['translations'].tolist()\n",
        "cohere_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# laser f1\n",
        "df = pd.read_csv('cohere/flores/laser_translations.csv')\n",
        "y_pred = df['translations'].tolist()\n",
        "laser_f1 = f1_score(y_true, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "tXGkOuuT6ZP_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cohere_f1, laser_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru9l5ny57z3E",
        "outputId": "2f27f93b-c9c3-48e9-c551-55e47f19a0e8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9496047430830039 0.03360712199824839\n"
          ]
        }
      ]
    }
  ]
}